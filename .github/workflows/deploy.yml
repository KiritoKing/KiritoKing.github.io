name: Deploy to Github Pages

on: 
  push:
    branches:
      - main
  workflow_dispatch:

jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
          # If your repository depends on submodule, please see: https://github.com/actions/checkout
          submodules: recursive
      - name: Use Node.js 20
        uses: actions/setup-node@v4
        with:
          # Examples: 20, 18.19, >=16.20.2, lts/Iron, lts/Hydrogen, *, latest, current, node
          # Ref: https://github.com/actions/setup-node#supported-version-syntax
          node-version: '20'
      - name: Cache NPM dependencies
        uses: actions/cache@v4
        with:
          path: node_modules
          key: ${{ runner.OS }}-npm-cache
          restore-keys: |
            ${{ runner.OS }}-npm-cache
      - name: Install Dependencies
        run: npm i -g yarn && yarn install --frozen-lockfile
      - name: Build
        run: yarn build
      - name: Upload Pages artifact
        uses: actions/upload-pages-artifact@v3
        with:
          path: ./public
      - name: Upload sitemap
        uses: actions/upload-artifact@v3
        with:
          name: sitemap
          path: ./public/sitemap.xml
  deploy:
    needs: build
    permissions:
      pages: write
      id-token: write
    environment:
      name: github-pages
      url: ${{ steps.deployment.outputs.page_url }}
    runs-on: ubuntu-latest
    steps:
      - name: Deploy to GitHub Pages
        id: deployment
        uses: actions/deploy-pages@v4

  submit-to-baidu:
    needs: deploy
    runs-on: ubuntu-latest
    steps:
      - name: Download sitemap
        uses: actions/download-artifact@v3
        with:
          name: sitemap
      - name: Extract and prepare URLs
        run: |
          grep -oP '(?<=<loc>).*(?=</loc>)' sitemap.xml > all_urls.txt
          sort all_urls.txt | uniq > unique_urls.txt
          if [ -f last_submitted_urls.txt ]; then
            comm -23 unique_urls.txt last_submitted_urls.txt > new_urls.txt
          else
            cp unique_urls.txt new_urls.txt
          fi
          head -n 50 new_urls.txt > urls_to_submit.txt
      - name: Submit URLs to Baidu
        run: |
          total_urls=$(wc -l < urls_to_submit.txt)
          echo "Total URLs to submit: $total_urls"
          
          split -l 20 urls_to_submit.txt url_chunk_
          
          for chunk in url_chunk_*; do
            echo "Submitting chunk: $chunk"
            response=$(curl -H 'Content-Type:text/plain' --data-binary @$chunk "http://data.zz.baidu.com/urls?site=https://chlorinec.top&token=${{ secrets.BAIDU_TOKEN }}")
            echo "Response: $response"
            sleep 5  # 添加较长的延迟，避免请求过于频繁
          done
          
          cp unique_urls.txt last_submitted_urls.txt
        env:
          BAIDU_TOKEN: ${{ secrets.BAIDU_TOKEN }}
      - name: Upload last submitted URLs
        uses: actions/upload-artifact@v3
        with:
          name: last_submitted_urls
          path: last_submitted_urls.txt